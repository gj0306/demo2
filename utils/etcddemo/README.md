#etcd 分布式key-value存储系统
开源的、高可用的分布式key-value存储系统

##etcd 应用场景
####场景一：服务发现
服务发现要解决的也是分布式系统中最常见的问题之一，即在同一个分布式集群中的进程或服务，要如何才能找到对方并建立连接。本质上来说，服务发现就是想要了解集群中是否有进程在监听 udp 或 tcp 端口，并且通过名字就可以查找和连接
####场景二：配置中心

etcd的应用场景优化都是围绕存储的东西是“配置” 来设定的。

配置的数据量通常都不大，所以默认etcd的存储上限是1GB  
配置通常对历史版本信息是比较关心的，所以etcd会保存 版本（revision） 信息  
配置变更是比较常见的，并且业务程序会需要实时知道，所以etcd提供了watch机制，基本就是实时通知配置变化  
配置的准确性一致性极其重要，所以etcd采用raft算法，保证系统的CP  
同一份配置通常会被大量客户端同时访问，针对这个做了grpc proxy对同一个key的watcher做了优化  
配置会被不同的业务部门使用，提供了权限控制和namespace机制  

####场景三：负载均衡
此处指的负载均衡均为软负载均衡，分布式系统中，为了保证服务的高可用以及数据的一致性，通常都会把数据和服务部署多份，以此达到对等服务，即使其中的某一个服务失效了，也不影响使用。由此带来的坏处是数据写入性能下降，而好处则是数据访问时的负载均衡。因为每个对等服务节点上都存有完整的数据，所以用户的访问流量就可以分流到不同的机器上。

####场景四：分布式锁
因为 etcd 使用 Raft 算法保持了数据的强一致性，某次操作存储到集群中的值必然是全局一致的，所以很容易实现分布式锁。
####场景五：集群监控与 Leader 竞选
通过 etcd 来进行监控实现起来非常简单并且实时性强。

前面几个场景已经提到 Watcher 机制，当某个节点消失或有变动时，Watcher 会第一时间发现并告知用户。  
节点可以设置TTL key，比如每隔 30s 发送一次心跳使代表该机器存活的节点继续存在，否则节点消失。  
这样就可以第一时间检测到各节点的健康状态，以完成集群的监控要求。  

另外，使用分布式锁，可以完成 Leader 竞选。这种场景通常是一些长时间 CPU 计算或者使用 IO 操作的机器，只需要竞选出的 Leader 计算或处理一次，就可以把结果复制给其他的 Follower。从而避免重复劳动，节省计算资源。

##etcd 分布式key-value存储系统 优点
简单：定义清晰、面向用户的API（gRPC）  

安全：可选的客户端TLS证书自动认证  

快速：支持每秒10,000次写入  

可靠：基于Raft算法确保强一致性  

##etcd与redis差异
redis在分布式环境下不是强一致性的，可能会丢失数据，或者读取不到最新数据

redis的数据变化监听机制没有etcd完善

etcd强一致性保证数据可靠性，导致性能上要低于redis

etcd和ZooKeeper是定位类似的项目，跟redis定位不一样

##etcd分布式锁及事务
排他性：任意时刻，只能有一个机器的一个线程能获取到锁  
容错性：只要分布式锁服务集群节点大部分存活，client就可以进行加锁解锁操作  
避免死锁：分布式锁一定能得到释放，即使client在释放之前崩溃  
